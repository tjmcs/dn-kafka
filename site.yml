# (c) 2016 DataNexus Inc.  All Rights Reserved
---
# First, build our kafka and zookeeper host groups
- name: Create kafka and zookeeper host groups
  hosts: "{{host_inventory}}"
  gather_facts: no
  tasks:
    - include_role:
        name: build-app-host-groups
      vars:
        host_group_list:
          - name: kafka
          - name: zookeeper
      when: cloud == 'aws' or cloud == 'osp'
    - include_role:
        name: build-app-host-groups
      vars:
        host_group_list:
          - { name: kafka, node_list: "{{host_inventory}}" }
          - { name: zookeeper, inventory: "{{zookeeper_inventory | default({})}}", node_list: "{{zookeeper_nodes | default([])}}" }
      when: cloud == "vagrant"

# Collect some Zookeeper related facts and determine the "private" IP addresses of
# the nodes in the Zookeeper ensemble (from their "public" IP addresses and the `data_iface`
# variable that was passed in as part of this playbook run) if a list of "public"  Zookeeper
# IP addresses was passed in.
- name: Gather facts from Zookeeper host group (if defined)
  hosts: zookeeper
  tasks: []

# Then, deploy Kafka to the nodes in the `host_inventory` that was passed in (if there
# is more than one node passed in, those nodes will be configured as a single Kafka cluster)
- name: Install/configure Kafka server(s)
  hosts: kafka
  gather_facts: no
  vars_files:
    - vars/kafka.yml
  vars:
    - combined_package_list: "{{ (default_packages|default([])) | union(kafka_package_list) | union((install_packages_by_tag|default({})).kafka|default([])) }}"
  # First, restart the network (unless the skip_network_restart was set)
  # and gather some facts about our Kafka node(s)
  pre_tasks:
    - name: Ensure the network interfaces are up on our Kafka node(s)
      service:
        name: network
        state: restarted
      become: true
      when: not (skip_network_restart is defined or skip_network_restart)
    - name: Gather facts from the Kafka node(s)
      setup:
    # next, we obtain the interface names for our data_iface
    # and api_iface (provided an interface description was provided for each)
    - include_role:
        name: get-iface-names
      vars:
        iface_descriptions: "{{iface_description_array}}"
      when: not (iface_description_array is undefined or iface_description_array == [])
    # and now that we know we have our data_iface identified, we can construct
    # the list of zk_nodes (the data_iface IP addresses of our zookeeper_nodes)
    - set_fact:
        zk_nodes: "{{(zookeeper_nodes | default([])) | map('extract', hostvars, [('ansible_' + data_iface), 'ipv4', 'address']) | list}}"
    # if we're provisioning a RHEL machine, then we need to ensure that
    # it's subscribed before we can install anything (if it hasn't been
    # registered already, of course, if that's the case then we can skip
    # this step)
    - block:
      - redhat_subscription:
          state: present
          username: "{{rhel_username}}"
          password: "{{rhel_password}}"
          consumer_id: "{{rhel_consumer_id}}"
        become: true
        when: rhel_username is defined and rhel_password is defined and rhel_consumer_id is defined
      when: ansible_distribution == 'RedHat'
  # Now that we have all of the facts we need, we can run the roles that are used to
  # deploy and configure Kafka
  roles:
    - role: get-iface-addr
      iface_name: "{{data_iface}}"
      as_fact: "data_addr"
    - role: get-iface-addr
      iface_name: "{{api_iface}}"
      as_fact: "api_addr"
    - role: setup-web-proxy
    - role: add-local-repository
      yum_repository: "{{yum_repo_url}}"
      when: yum_repo_url is defined
    - role: install-packages
      package_list: "{{combined_package_list}}"
    - role: dn-kafka
