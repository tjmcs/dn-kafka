#!/usr/bin/env ansible-playbook
#
# (c) 2016 DataNexus Inc.  All Rights Reserved
---
# Build our kafka and zookeeper host groups
- name: Create kafka and zookeeper host groups
  hosts: localhost
  gather_facts: no
  tasks:
    # if we're using dynamic provisioning; build the host groups from the
    # meta-data associated with the matching nodes in the selected cloud
    - block:
      # load the 'local variables file', if one was defined, to get any variables
      # we might need from that file when constructing our host groups
      - name: Load local variables file
        include_vars:
          file: "{{local_vars_file}}"
        when: not (local_vars_file is undefined or local_vars_file is none or local_vars_file | trim == '')
      # then, build our host groups
      - include_role:
          name: build-app-host-groups
        vars:
          host_group_list:
            - name: kafka
            - name: zookeeper
      when: cloud is defined and (cloud == 'aws' or cloud == 'osp')

# Collect some Zookeeper related facts and determine the "private" IP addresses of
# the nodes in the Zookeeper ensemble (from their "public" IP addresses and the `data_iface`
# variable that was passed in as part of this playbook run) if a list of "public"  Zookeeper
# IP addresses was passed in.
- name: Gather facts from Zookeeper host group (if defined)
  hosts: zookeeper
  tasks: []

# Deploy Kafka to the nodes in the `kafka` host group (this group must be
# defined in the static inventory file that was input, if one was used, or
# built from the dynamic inventory and the input tags if we're deploying to
# an AWS or OpenStack cloud); note that if there is more than one node in
# the `kafka` host group, those nodes will be configured as a Kafka cluster
- name: Install/configure Kafka server(s)
  hosts: kafka
  gather_facts: no
  vars_files:
    - vars/kafka.yml
  vars:
    - combined_package_list: "{{ (default_packages|default([])) | union(kafka_package_list) | union((install_packages_by_tag|default({})).kafka|default([])) }}"
    - kafka_nodes: "{{groups['kafka']}}"
    - zookeeper_nodes: "{{groups['zookeeper']}}"
  pre_tasks:
    # first, load the local variables file (if one was defined); this will initialize
    # the variables used in our playbook (and override any values in the 'vars/kafka.yml'
    # file with redefined values from the 'local_vars_file', if any)
    - name: Load local variables file (if defined)
      include_vars:
        file: "{{local_vars_file}}"
      when: not (local_vars_file is undefined or local_vars_file is none or local_vars_file | trim == '')
    # then, restart the network (unless the skip_network_restart was set)
    # and gather some facts about our Kafka node(s)
    - name: Ensure the network interfaces are up on our Kafka node(s)
      service:
        name: network
        state: restarted
      become: true
      when: not (skip_network_restart is defined or skip_network_restart)
    - name: Gather facts from the Kafka node(s)
      setup:
    # next, we obtain the interface names for our data_iface
    # and api_iface (provided an interface description was provided for each)
    - include_role:
        name: get-iface-names
      vars:
        iface_descriptions: "{{iface_description_array}}"
      when: not (iface_description_array is undefined or iface_description_array == [])
    # and now that we know we have our data_iface identified, we can construct
    # the list of zk_nodes (the data_iface IP addresses of our zookeeper_nodes)
    - set_fact:
        zk_nodes: "{{(zookeeper_nodes | default([])) | map('extract', hostvars, [('ansible_' + data_iface), 'ipv4', 'address']) | list}}"
    # if we're provisioning a RHEL machine, then we need to ensure that
    # it's subscribed before we can install anything (if it hasn't been
    # registered already, of course, if that's the case then we can skip
    # this step)
    - block:
      - redhat_subscription:
          state: present
          username: "{{rhel_username}}"
          password: "{{rhel_password}}"
          consumer_id: "{{rhel_consumer_id}}"
        become: true
        when: rhel_username is defined and rhel_password is defined and rhel_consumer_id is defined
      when: ansible_distribution == 'RedHat'
  # Now that we have all of the facts we need, we can run the roles that are used to
  # deploy and configure Kafka
  roles:
    - role: get-iface-addr
      iface_name: "{{data_iface}}"
      as_fact: "data_addr"
    - role: get-iface-addr
      iface_name: "{{api_iface}}"
      as_fact: "api_addr"
    - role: setup-web-proxy
    - role: add-local-repository
      yum_repository: "{{yum_repo_url}}"
      when: yum_repo_url is defined
    - role: install-packages
      package_list: "{{combined_package_list}}"
    - role: dn-kafka
